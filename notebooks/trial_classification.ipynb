{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from hypnose_analysis.utils.classification_utils import *\n",
    "from hypnose_analysis.processing.detect_settings import *\n",
    "from hypnose_analysis.processing.detect_stage import *\n",
    "from pathlib import Path\n",
    "import harp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import aeon.io.video as video\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os\n",
    "import zoneinfo\n",
    "from datetime import datetime, timezone\n",
    "from functools import reduce\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Date or SubjID Analysis. Can analyze all Sessions for given SubjID (run on subjid only), all SubjIDs for a date (run on date only), or specific SubjID(s) and Date(s) (run on lists of each)\n",
    "# To analyze all subjids for a date, or vice versa, set the other argument to None\n",
    "# For Dates: use lists for specific dates [YYYYMMDD], or use range(start_date, end_date) for a date range (inclusive)\n",
    "\n",
    "subjids = [40]\n",
    "dates = [20251212]\n",
    "\n",
    "multi_run_results = batch_analyze_sessions(subjids=subjids, dates=dates, save=True, verbose=False, print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected stage from metadata: quintuples\n",
      "No hidden rule indices found\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "SUMMARY: TRIAL CLASSIFICATION AND POKE TIME ANALYSIS FOR SUBJECT [40] DATE [20251120]\n",
      "================================================================================ \n",
      "\n",
      "================================================================================\n",
      "Sample offset time: 200.0 ms\n",
      "Minimum sampling time (default): 350.0 ms\n",
      "Minimum sampling times (ms) by odor:\n",
      "  - OdorA: 200.0\n",
      "  - OdorB: 200.0\n",
      "  - OdorC: 350.0\n",
      "  - OdorD: 350.0\n",
      "  - OdorE: 350.0\n",
      "  - OdorF: 350.0\n",
      "  - OdorG: 350.0\n",
      "Response time window: 2.00 s\n",
      "\n",
      "TRIAL CLASSIFICATIONs:\n",
      "Hidden Rule Locations: Positions None (indices None)\n",
      "\n",
      "Hidden Rule Odors: None\n",
      "\n",
      "Total attempts: 248\n",
      "-- Non-initiated sequences (total): 85 (34.3%)\n",
      "    -- Position 1 attempts within trials 0 (0.0%)\n",
      "    -- Baseline non-initiated sequences 85 (100.0%)\n",
      "-- Initiated sequences (\u001b[1mtrials\u001b[0m]): 163 (65.7%)\n",
      "\n",
      "INITIATED TRIALS BREAKDOWN:\n",
      "-- Completed sequences: 132 ( 81.0%)\n",
      "-- Hidden Rule Trials (HR): 0 (0.0%)\n",
      "   -- Hidden Rule Trials Rewarded: 0 (0.0%)\n",
      "   -- Hidden Rule Missed: 0 (0.0%)\n",
      "-- Aborted sequences: 31 ( 19.0%)\n",
      "   -- Aborted Hidden Rule trials (HR): 0 (0.0%)\n",
      "\n",
      "REWARDED TRIALS BREAKDOWN:\n",
      "-- Rewarded: 124 (93.9%)\n",
      "-- Unrewarded: 1 (0.8%)\n",
      "-- Reward Timeout: 7 (5.3%)\n",
      "\n",
      "POKE TIME RANGES BY POSITION:\n",
      "----------------------------------------\n",
      "Position 1: 133.6 - 1030.0ms (avg: 898.1ms, n=132)\n",
      "Position 2: 238.2 - 1022.0ms (avg: 944.2ms, n=132)\n",
      "Position 3: 285.8 - 1021.0ms (avg: 957.4ms, n=132)\n",
      "Position 4: 285.2 - 1023.0ms (avg: 956.9ms, n=132)\n",
      "Position 5: 194.3 - 876.6ms (avg: 533.1ms, n=132)\n",
      "\n",
      "VALVE TIME RANGES BY POSITION:\n",
      "----------------------------------------\n",
      "Position 1: 569.0 - 1030.0ms (avg: 966.9ms, n=132)\n",
      "Position 2: 581.0 - 1022.0ms (avg: 993.1ms, n=132)\n",
      "Position 3: 570.0 - 1025.0ms (avg: 996.3ms, n=132)\n",
      "Position 4: 560.0 - 1024.0ms (avg: 986.6ms, n=132)\n",
      "Position 5: 408.0 - 1030.0ms (avg: 754.0ms, n=132)\n",
      "\n",
      "POKE TIME RANGES BY ODOR (ALL POSITIONS):\n",
      "--------------------------------------------------\n",
      "OdorA: 194.3 - 876.6ms (avg: 528.9ms, n=59)\n",
      "OdorB: 335.7 - 805.8ms (avg: 536.5ms, n=73)\n",
      "OdorC: 133.6 - 1021.0ms (avg: 906.2ms, n=106)\n",
      "OdorD: 285.2 - 1030.0ms (avg: 933.5ms, n=109)\n",
      "OdorE: 369.4 - 1019.9ms (avg: 962.5ms, n=108)\n",
      "OdorF: 176.3 - 1018.0ms (avg: 935.9ms, n=104)\n",
      "OdorG: 355.2 - 1024.0ms (avg: 958.2ms, n=101)\n",
      "\n",
      "VALVE TIME RANGES BY ODOR (ALL POSITIONS):\n",
      "--------------------------------------------------\n",
      "OdorA: 408.0 - 1030.0ms (avg: 755.3ms, n=59)\n",
      "OdorB: 546.0 - 1010.0ms (avg: 753.0ms, n=73)\n",
      "OdorC: 564.0 - 1024.0ms (avg: 984.1ms, n=106)\n",
      "OdorD: 560.0 - 1030.0ms (avg: 982.8ms, n=109)\n",
      "OdorE: 581.0 - 1022.0ms (avg: 994.4ms, n=108)\n",
      "OdorF: 569.0 - 1018.0ms (avg: 981.1ms, n=104)\n",
      "OdorG: 564.0 - 1024.0ms (avg: 986.0ms, n=101)\n",
      "\n",
      "NON-INITIATED TRIALS POKE TIMES:\n",
      "----------------------------------------\n",
      "Baseline non-initiated: n=85 median=145.6 ms range=0.0-342.8 ms\n",
      "Pos1 attempts: n=0 (no valid poke times)\n",
      "================================================================================\n",
      "RESPONSE TIME ANALYSIS - ALL COMPLETED TRIALS\n",
      "================================================================================\n",
      "Total completed trials: 132\n",
      "\n",
      "RESPONSE TIME ANALYSIS RESULTS:\n",
      "Total completed trials analyzed: 132\n",
      "Failed response time calculations: 2\n",
      "Successful response time calculations: 130\n",
      "\n",
      "REWARDED TRIALS:\n",
      "  Count: 123\n",
      "  Range: 1490.4 - 2393.2ms\n",
      "  Average: 1810.7ms\n",
      "  Median: 1791.3ms\n",
      "\n",
      "HR REWARDED TRIALS (response times): none\n",
      "\n",
      "UNREWARDED TRIALS:\n",
      "  Count: 1\n",
      "  Range: 2232.7 - 2232.7ms\n",
      "  Average: 2232.7ms\n",
      "  Median: 2232.7ms\n",
      "\n",
      "REWARD TIMEOUT TRIALS:\n",
      "  Count: 6\n",
      "  Range: 1855.7 - 4892.0ms\n",
      "  Average: 2728.8ms\n",
      "  Median: 2452.5ms\n",
      "\n",
      "ALL TRIALS WITH RESPONSE TIMES:\n",
      "  Count: 130\n",
      "  Range: 1490.4 - 4892.0ms\n",
      "  Average: 1856.3ms\n",
      "  Median: 1800.7ms\n",
      "================================================================================\n",
      "ABORTED TRIALS CLASSIFICATION SUMMARY\n",
      "================================================================================\n",
      "- Total Aborted Trials: 31\n",
      "  - Re-Initiation Abortions: 11 (35.5%)\n",
      "  - Initiation Abortions:    20 (64.5%)\n",
      "\n",
      "False Alarms:\n",
      "  - non-FA Abortions: 1 (3.2%)\n",
      "  - False Alarm abortions: 30 (96.8%)\n",
      "      - FA Time In - Within Response Time Window (2.0 s):  3 (10.0%)\n",
      "          - Response Time: median=1866.8 ms, avg=1843.1 ms, range: 1732.9 - 1929.6 ms\n",
      "      - FA Time Out - Up to 3x Response Time Window (2-6 s):  8 (26.7%)\n",
      "          - Response Time: median=2588.0 ms, avg=2832.5 ms, range: 2179.3 - 3865.7 ms\n",
      "      - FA Late - After 3x Response Time up to next trial: 19 (63.3%)\n",
      "          - Response Time: median=21535.3 ms, avg=31031.1 ms, range: 7862.4 - 175216.4 ms\n",
      "\n",
      "False Alarm Classification for Non-Initiated Trials:\n",
      "  Total Non-Initiated FA Trials: 85\n",
      "   - Non-False Alarm: 78 (91.8%)\n",
      "   - FA Time In (Within Response Time): 0 (0.0%)\n",
      "   - FA Time Out (Up to 3x Response Time): 0 (0.0%)\n",
      "   - FA Late (> 3x Response Time): 7 (8.2%)\n",
      "\n",
      "Poke Times for all Odors (Except aborted Odor):\n",
      "  - All Odors (except aborted): n=50 | median=1004.0 ms | avg=895.0 ms | range=361.8-1015.0 ms\n",
      "  - Position 1: n=25 | median=1004.0 ms | avg=843.8 ms | range=361.8-1011.0 ms\n",
      "  - Position 2: n=14 | median=995.0 ms | avg=930.3 ms | range=509.9-1012.0 ms\n",
      "  - Position 3: n=9 | median=992.1 ms | avg=957.4 ms | range=746.6-1015.0 ms\n",
      "  - Position 4: n=2 | median=1006.5 ms | avg=1006.5 ms | range=1006.0-1007.0 ms\n",
      "  - Odor OdorC: n=6 | median=877.7 ms | avg=796.0 ms | range=361.8-965.6 ms\n",
      "  - Odor OdorD: n=8 | median=976.5 ms | avg=779.3 ms | range=371.4-1010.0 ms\n",
      "  - Odor OdorE: n=11 | median=1004.0 ms | avg=968.7 ms | range=718.4-1014.0 ms\n",
      "  - Odor OdorF: n=14 | median=1006.5 ms | avg=863.1 ms | range=367.5-1015.0 ms\n",
      "  - Odor OdorG: n=11 | median=1010.0 ms | avg=1000.0 ms | range=952.7-1011.0 ms\n",
      "\n",
      "Aborted Odor Poke Times:\n",
      "  - Re-Initiation Abortions: n=11 | median=526.2 ms | avg=638.0 ms | range=354.2-1013.0 ms\n",
      "  - Initiation Abortions: n=20 | median=253.6 ms | avg=230.2 ms | range=0.0-338.0 ms\n",
      "\n",
      "Counts by last odor:\n",
      "  - OdorA: 1 abortions, Re-initiation 1, Initiation 0\n",
      "  - OdorB: 1 abortions, Re-initiation 0, Initiation 1\n",
      "  - OdorC: 7 abortions, Re-initiation 0, Initiation 7\n",
      "  - OdorD: 7 abortions, Re-initiation 3, Initiation 4\n",
      "  - OdorE: 7 abortions, Re-initiation 3, Initiation 4\n",
      "  - OdorF: 4 abortions, Re-initiation 1, Initiation 3\n",
      "  - OdorG: 4 abortions, Re-initiation 3, Initiation 1\n",
      "\n",
      "Counts by last position:\n",
      "  - Position 1: 6 abortions, Re-initiation 6, Initiation 0\n",
      "  - Position 2: 11 abortions, Re-initiation 4, Initiation 7\n",
      "  - Position 3: 5 abortions, Re-initiation 0, Initiation 5\n",
      "  - Position 4: 7 abortions, Re-initiation 0, Initiation 7\n",
      "  - Position 5: 2 abortions, Re-initiation 1, Initiation 1\n",
      "\n",
      "Saved merged session summary to \\\\ceph-gw02.hpc.swc.ucl.ac.uk\\harris\\hypnose\\derivatives\\sub-040_id-259\\ses-019_date-20251120\\saved_analysis_results\\merged_summary_40_20251120.txt\n",
      "[save] Success: results saved to: \\\\ceph-gw02.hpc.swc.ucl.ac.uk\\harris\\hypnose\\derivatives\\sub-040_id-259\\ses-019_date-20251120\\saved_analysis_results\n"
     ]
    }
   ],
   "source": [
    "res = analyze_session_multi_run_by_id_date(40, 20251120, verbose=False, print_summary=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading experiments --> just define the SUBJID and DATE\n",
    "root = load_experiment(48, 20251210, index=1) #can add index for multiple experiments; index=0 as default\n",
    "stage = detect_stage(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = load_experiment(38, 20251212, index=0)\n",
    "time_window = ('15:46:30', '15:47:30')\n",
    "plot_valve_activity = plot_valve_and_poke_events(root=root, time_window=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_all_streams(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = load_experiment_events(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odor_map = load_odor_mapping(root, data=data, verbose=True)\n",
    "print(\"Data streams loaded:\", list(data.keys()))\n",
    "print(\"Event types loaded:\", list(events.keys()))\n",
    "print(\"Odor mapping:\", odor_map['odour_to_olfactometer_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_counts = detect_trials(data, events, root, odor_map, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_outcomes_complete = classify_and_analyze_with_response_times(data, events, trial_counts, odor_map, stage, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare recent res results to previously saved results\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load old data\n",
    "json_path = Path(\"/Volumes/harris/hypnose/derivatives/sub-039_id-258/ses-012_date-20251112/saved_analysis_results\")\n",
    "df_old_csv_path = json_path / \"completed_sequences.csv\"\n",
    "\n",
    "if df_old_csv_path.exists():\n",
    "    df_old = pd.read_csv(df_old_csv_path)\n",
    "    print(f\"Loaded old data from: {df_old_csv_path}\")\n",
    "else:\n",
    "    print(f\"File not found: {df_old_csv_path}\")\n",
    "    df_old = pd.DataFrame()\n",
    "\n",
    "# Load new data\n",
    "cls = res['classification']\n",
    "df_new = cls['completed_sequences']\n",
    "\n",
    "# Print counts\n",
    "print(f\"\\nOld completed_sequences (from CSV): {len(df_old)} entries\")\n",
    "print(f\"New completed_sequences (from res): {len(df_new)} entries\")\n",
    "\n",
    "# Get unique initiation_sequence_time values\n",
    "old_times = set(pd.to_datetime(df_old['initiation_sequence_time'], errors='coerce').dropna())\n",
    "new_times = set(pd.to_datetime(df_new['initiation_sequence_time'], errors='coerce').dropna())\n",
    "\n",
    "# Find differences\n",
    "only_in_old = old_times - new_times\n",
    "only_in_new = new_times - old_times\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Unique initiation_sequence_time in old but not in new: {len(only_in_old)}\")\n",
    "print(f\"{'='*80}\")\n",
    "if only_in_old:\n",
    "    old_mask = pd.to_datetime(df_old['initiation_sequence_time'], errors='coerce').isin(only_in_old)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(df_old[old_mask])\n",
    "else:\n",
    "    print(\"None\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Unique initiation_sequence_time in new but not in old: {len(only_in_new)}\")\n",
    "print(f\"{'='*80}\")\n",
    "if only_in_new:\n",
    "    new_mask = pd.to_datetime(df_new['initiation_sequence_time'], errors='coerce').isin(only_in_new)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(df_new[new_mask])\n",
    "else:\n",
    "    print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find completed rows whose initiation_sequence_time is present (not-null)\n",
    "# but not present in completed_sequences_HR_missed\n",
    "cls = res.get('classification', {})\n",
    "\n",
    "completed = cls.get('completed_sequences', pd.DataFrame())\n",
    "hr_missed = cls.get('completed_sequences_HR_missed', cls.get('completed_sequences_hr_missed', pd.DataFrame()))\n",
    "\n",
    "if 'initiation_sequence_time' not in completed.columns:\n",
    "    print(\"completed_sequences has no 'initiation_sequence_time' column.\")\n",
    "else:\n",
    "    hr_times = hr_missed['initiation_sequence_time'] if 'initiation_sequence_time' in hr_missed.columns else pd.Series(dtype='datetime64[ns]')\n",
    "    hr_set = set(hr_times.dropna())\n",
    "\n",
    "    mask = completed['initiation_sequence_time'].notna() & ~completed['initiation_sequence_time'].isin(hr_set)\n",
    "    diff_df = completed[mask].copy()\n",
    "\n",
    "    print(f\"Rows in completed_sequences with initiation_sequence_time not in completed_sequences_HR_missed: {len(diff_df)}\")\n",
    "    display(diff_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count completed_sequences with odor_sequence length < 5 (and > 5) and print them\n",
    "cls = res.get('classification', res)\n",
    "completed = cls.get('completed_sequences', pd.DataFrame())\n",
    "\n",
    "if 'odor_sequence' not in completed.columns:\n",
    "    print(\"completed_sequences has no 'odor_sequence' column.\")\n",
    "else:\n",
    "    def _to_list(seq):\n",
    "        if isinstance(seq, (list, tuple)):\n",
    "            return list(seq)\n",
    "        if pd.isna(seq):\n",
    "            return []\n",
    "        if isinstance(seq, str):\n",
    "            s = seq.strip()\n",
    "            try:\n",
    "                v = ast.literal_eval(s)\n",
    "                if isinstance(v, (list, tuple)):\n",
    "                    return list(v)\n",
    "            except Exception:\n",
    "                pass\n",
    "            s2 = s.strip(\"[]\")\n",
    "            parts = [p.strip().strip(\"'\\\"\") for p in s2.split(\",\") if p.strip()]\n",
    "            return parts\n",
    "        return []\n",
    "\n",
    "    seq_lens = completed['odor_sequence'].apply(lambda x: len(_to_list(x)))\n",
    "    short_mask = seq_lens < 5\n",
    "    long_mask = seq_lens > 5\n",
    "\n",
    "    short_df = completed[short_mask].copy()\n",
    "    long_df = completed[long_mask].copy()\n",
    "\n",
    "    print(f\"Completed sequences with odor_sequence length < 5: {len(short_df)}\")\n",
    "    if not short_df.empty:\n",
    "        display(short_df)\n",
    "\n",
    "    print(f\"Completed sequences with odor_sequence length > 5: {len(long_df)}\")\n",
    "    if not long_df.empty:\n",
    "        display(long_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = res['classification']\n",
    "# Code like this can be used to extract data from res. This will display all trials with < threshold poke times in completed sequences\n",
    "comp = cls[\"completed_sequences_with_response_times\"]\n",
    "pos_pokes_all = build_position_pokes_table(cls)\n",
    "short_pokes = build_position_pokes_table(cls, threshold_ms=200)\n",
    "display(short_pokes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max rewarded trials in any 60s window: 4\n",
      "Window: 2025-11-20T14:37:36.411488000 to 2025-11-20T14:38:36.411488000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initiation_sequence_time</th>\n",
       "      <th>sequence_start</th>\n",
       "      <th>sequence_end</th>\n",
       "      <th>continuous_poke_time_ms</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>attempt_number</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>required_min_sampling_time_ms</th>\n",
       "      <th>odor_name</th>\n",
       "      <th>odor_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>first_supply_time</th>\n",
       "      <th>first_supply_port</th>\n",
       "      <th>first_supply_odor_identity</th>\n",
       "      <th>supply1_count</th>\n",
       "      <th>supply2_count</th>\n",
       "      <th>total_supply_count</th>\n",
       "      <th>run_id</th>\n",
       "      <th>trial_time</th>\n",
       "      <th>trial_time_rel_sec</th>\n",
       "      <th>trial_time_rel_hmsms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-11-20 14:37:13.306080</td>\n",
       "      <td>2025-11-20 14:37:36.411488</td>\n",
       "      <td>2025-11-20 14:37:46.733984</td>\n",
       "      <td>361.920</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-20 14:37:36.411488</td>\n",
       "      <td>350.0</td>\n",
       "      <td>OdorD</td>\n",
       "      <td>[OdorD, OdorF, OdorC, OdorG, OdorB]</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-20 14:37:43.713504000</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-20 14:37:36.411488</td>\n",
       "      <td>2402.681984</td>\n",
       "      <td>00:40:02:682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-11-20 14:37:46.733984</td>\n",
       "      <td>2025-11-20 14:37:55.320480</td>\n",
       "      <td>2025-11-20 14:38:05.489984</td>\n",
       "      <td>376.608</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-20 14:37:55.320480</td>\n",
       "      <td>350.0</td>\n",
       "      <td>OdorC</td>\n",
       "      <td>[OdorC, OdorD, OdorG, OdorF, OdorA]</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-20 14:38:02.463488000</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-20 14:37:55.320480</td>\n",
       "      <td>2421.590976</td>\n",
       "      <td>00:40:21:591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-11-20 14:38:05.489984</td>\n",
       "      <td>2025-11-20 14:38:15.203488</td>\n",
       "      <td>2025-11-20 14:38:24.700000</td>\n",
       "      <td>516.448</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-20 14:38:15.203488</td>\n",
       "      <td>350.0</td>\n",
       "      <td>OdorE</td>\n",
       "      <td>[OdorE, OdorF, OdorD, OdorC, OdorB]</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-20 14:38:21.684480000</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-20 14:38:15.203488</td>\n",
       "      <td>2441.473984</td>\n",
       "      <td>00:40:41:474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-11-20 14:38:24.700000</td>\n",
       "      <td>2025-11-20 14:38:30.972480</td>\n",
       "      <td>2025-11-20 14:38:41.560992</td>\n",
       "      <td>484.128</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-20 14:38:30.972480</td>\n",
       "      <td>350.0</td>\n",
       "      <td>OdorG</td>\n",
       "      <td>[OdorG, OdorC, OdorE, OdorF, OdorB]</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-20 14:38:38.535487999</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-20 14:38:30.972480</td>\n",
       "      <td>2457.242976</td>\n",
       "      <td>00:40:57:243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     initiation_sequence_time             sequence_start  \\\n",
       "27 2025-11-20 14:37:13.306080 2025-11-20 14:37:36.411488   \n",
       "28 2025-11-20 14:37:46.733984 2025-11-20 14:37:55.320480   \n",
       "29 2025-11-20 14:38:05.489984 2025-11-20 14:38:15.203488   \n",
       "30 2025-11-20 14:38:24.700000 2025-11-20 14:38:30.972480   \n",
       "\n",
       "                 sequence_end  continuous_poke_time_ms  trial_id  \\\n",
       "27 2025-11-20 14:37:46.733984                  361.920        36   \n",
       "28 2025-11-20 14:38:05.489984                  376.608        37   \n",
       "29 2025-11-20 14:38:24.700000                  516.448        38   \n",
       "30 2025-11-20 14:38:41.560992                  484.128        39   \n",
       "\n",
       "    attempt_number                  timestamp  required_min_sampling_time_ms  \\\n",
       "27               2 2025-11-20 14:37:36.411488                          350.0   \n",
       "28               2 2025-11-20 14:37:55.320480                          350.0   \n",
       "29               1 2025-11-20 14:38:15.203488                          350.0   \n",
       "30               1 2025-11-20 14:38:30.972480                          350.0   \n",
       "\n",
       "   odor_name                        odor_sequence  ...  \\\n",
       "27     OdorD  [OdorD, OdorF, OdorC, OdorG, OdorB]  ...   \n",
       "28     OdorC  [OdorC, OdorD, OdorG, OdorF, OdorA]  ...   \n",
       "29     OdorE  [OdorE, OdorF, OdorD, OdorC, OdorB]  ...   \n",
       "30     OdorG  [OdorG, OdorC, OdorE, OdorF, OdorB]  ...   \n",
       "\n",
       "               first_supply_time first_supply_port first_supply_odor_identity  \\\n",
       "27 2025-11-20 14:37:43.713504000                 2                          B   \n",
       "28 2025-11-20 14:38:02.463488000                 1                          A   \n",
       "29 2025-11-20 14:38:21.684480000                 2                          B   \n",
       "30 2025-11-20 14:38:38.535487999                 2                          B   \n",
       "\n",
       "   supply1_count supply2_count total_supply_count run_id  \\\n",
       "27             0             1                  1      1   \n",
       "28             1             0                  1      1   \n",
       "29             0             1                  1      1   \n",
       "30             0             1                  1      1   \n",
       "\n",
       "                   trial_time trial_time_rel_sec  trial_time_rel_hmsms  \n",
       "27 2025-11-20 14:37:36.411488        2402.681984          00:40:02:682  \n",
       "28 2025-11-20 14:37:55.320480        2421.590976          00:40:21:591  \n",
       "29 2025-11-20 14:38:15.203488        2441.473984          00:40:41:474  \n",
       "30 2025-11-20 14:38:30.972480        2457.242976          00:40:57:243  \n",
       "\n",
       "[4 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find X s window with the most rewarded trials - used to find video segments\n",
    "window_sec = 60\n",
    "\n",
    "def find_peak_rewarded_window(res, window_sec=40):\n",
    "    # Get rewarded trials table\n",
    "    cls = res.get(\"classification\", res)\n",
    "    df = cls.get(\"completed_sequence_rewarded\", pd.DataFrame())\n",
    "    if df.empty:\n",
    "        print(\"No rewarded trials found.\")\n",
    "        return None\n",
    "\n",
    "    # Use valve_open_ts as trial time (or poke_first_in if you prefer)\n",
    "    times = pd.to_datetime(df[\"sequence_start\"], errors=\"coerce\")\n",
    "    df = df.assign(trial_time=times)\n",
    "    df = df.dropna(subset=[\"trial_time\"]).sort_values(\"trial_time\").reset_index(drop=True)\n",
    "\n",
    "    # Add relative time from start (seconds and HH:MM:SS:MS) to align with video timeline\n",
    "    start_time = df[\"trial_time\"].min()\n",
    "    deltas = df[\"trial_time\"] - start_time\n",
    "    rel_ms = deltas.dt.total_seconds() * 1000.0\n",
    "\n",
    "    def _fmt_ms(ms):\n",
    "        if pd.isna(ms):\n",
    "            return None\n",
    "        ms_int = int(round(ms))\n",
    "        hours, rem = divmod(ms_int, 3600_000)\n",
    "        minutes, rem = divmod(rem, 60_000)\n",
    "        seconds, millis = divmod(rem, 1000)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d}:{millis:03d}\"\n",
    "\n",
    "    df = df.assign(\n",
    "        trial_time_rel_sec=rel_ms / 1000.0,\n",
    "        trial_time_rel_hmsms=rel_ms.apply(_fmt_ms),\n",
    "    )\n",
    "\n",
    "    # Find the window with the most rewarded trials\n",
    "    best_count = 0\n",
    "    best_start = None\n",
    "    best_end = None\n",
    "    best_indices = []\n",
    "\n",
    "    trial_times = df[\"trial_time\"].values\n",
    "    n = len(trial_times)\n",
    "    for i in range(n):\n",
    "        start = trial_times[i]\n",
    "        end = start + np.timedelta64(window_sec, \"s\")\n",
    "        # Find all trials within [start, end)\n",
    "        mask = (trial_times >= start) & (trial_times < end)\n",
    "        count = mask.sum()\n",
    "        if count > best_count:\n",
    "            best_count = count\n",
    "            best_start = start\n",
    "            best_end = end\n",
    "            best_indices = np.where(mask)[0]\n",
    "\n",
    "    print(f\"Max rewarded trials in any {window_sec}s window: {best_count}\")\n",
    "    print(f\"Window: {best_start} to {best_end}\")\n",
    "    # Optionally display the trials in that window (includes trial_time_rel_sec and HH:MM:SS:MS)\n",
    "    display(df.iloc[best_indices])\n",
    "    return df.iloc[best_indices]\n",
    "\n",
    "peak_window_trials = find_peak_rewarded_window(res, window_sec=window_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting video segments around start and end times. E.g., used to get video around peak rewarded trials identified above. \n",
    "# Automatically finds correct file, but runs faster if index is specified\n",
    "# specify 30 or 60 fps (fps mismatch visible if video duration is not matching input duration)\n",
    "start_time = \"14:34:29\"\n",
    "end_time = \"14:35:46\"\n",
    "cut_video(38, 20251119, start_time, end_time, fps=60, show_odor_overlay=True)#, vertical_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of new functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Functions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick code to look for brief purge events in between odors in completed trials\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bisect import bisect_left, bisect_right\n",
    "\n",
    "def list_short_purge_between_odors(trial_outcomes_complete, odor_map, threshold_ms=200.0, onset_slack_ms=50.0, verbose=True):\n",
    "    \"\"\"\n",
    "    Find Purge events shorter than threshold_ms that occur between distinct odor presentations\n",
    "    in completed trials. A Purge onset is counted if it lies within:\n",
    "       [current_odor_end - onset_slack_ms, next_odor_start + onset_slack_ms]\n",
    "    Returns a list of dicts (one per event) and prints a summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Helpers to resolve Purge columns ---\n",
    "    def _ci_get(d, key):\n",
    "        if not isinstance(d, dict):\n",
    "            return None\n",
    "        lk = str(key).lower()\n",
    "        for k, v in d.items():\n",
    "            if str(k).lower() == lk:\n",
    "                return v\n",
    "        return None\n",
    "\n",
    "    def _col_to_idx(col, row_len=None):\n",
    "        if isinstance(col, (int, np.integer)):\n",
    "            idx_num = int(col)\n",
    "        else:\n",
    "            m = re.search(r'(\\d+)', str(col))\n",
    "            if not m:\n",
    "                return None\n",
    "            idx_num = int(m.group(1))\n",
    "        if row_len is None:\n",
    "            return idx_num\n",
    "        if 0 <= idx_num < row_len:\n",
    "            return idx_num\n",
    "        if 1 <= idx_num <= row_len:\n",
    "            return idx_num - 1\n",
    "        return None\n",
    "\n",
    "    def _resolve_odor_name(odor_map, olf_id, idx, col=None):\n",
    "        v2o = odor_map.get(\"valve_to_odor\", {})\n",
    "        if isinstance(v2o, dict):\n",
    "            name = v2o.get((olf_id, idx))\n",
    "            if name is None and col is not None:\n",
    "                name = v2o.get(col)\n",
    "            if name is None:\n",
    "                name = v2o.get(idx)\n",
    "            if isinstance(name, str):\n",
    "                return name\n",
    "        grid = odor_map.get(\"odour_to_olfactometer_map\") or odor_map.get(\"odor_to_olfactometer_map\")\n",
    "        if isinstance(grid, (list, tuple)) and len(grid) > olf_id and isinstance(grid[olf_id], (list, tuple)):\n",
    "            row = grid[olf_id]\n",
    "            if 0 <= idx < len(row):\n",
    "                return row[idx]\n",
    "        return None\n",
    "\n",
    "    def _purge_columns(odor_map):\n",
    "        cols = []\n",
    "        olf_valves = odor_map[\"olfactometer_valves\"]\n",
    "        grid = odor_map.get(\"odour_to_olfactometer_map\") or odor_map.get(\"odor_to_olfactometer_map\")\n",
    "        for olf_id, df in olf_valves.items():\n",
    "            if df is None or getattr(df, \"empty\", True):\n",
    "                continue\n",
    "            row_len = len(grid[olf_id]) if isinstance(grid, (list, tuple)) and len(grid) > olf_id else None\n",
    "            for col in df.columns:\n",
    "                idx = _col_to_idx(col, row_len=row_len)\n",
    "                if idx is None:\n",
    "                    continue\n",
    "                name = _resolve_odor_name(odor_map, olf_id, idx, col=col)\n",
    "                if isinstance(name, str) and name.lower() == \"purge\":\n",
    "                    cols.append((olf_id, idx, col))\n",
    "        return cols\n",
    "\n",
    "    def _purge_events(odor_map):\n",
    "        \"\"\"Return list of dicts: {start,end,duration_ms,olf_id,idx,col} across all purge columns.\"\"\"\n",
    "        evs = []\n",
    "        for olf_id, idx, col in _purge_columns(odor_map):\n",
    "            df = odor_map[\"olfactometer_valves\"][olf_id]\n",
    "            if df is None or getattr(df, \"empty\", True):\n",
    "                continue\n",
    "            s = df[col].astype(bool)\n",
    "            rises = s & ~s.shift(1, fill_value=False)\n",
    "            falls = ~s & s.shift(1, fill_value=False)\n",
    "            starts = list(s.index[rises])\n",
    "            ends = list(s.index[falls])\n",
    "            i = j = 0\n",
    "            while i < len(starts) and j < len(ends):\n",
    "                if ends[j] <= starts[i]:\n",
    "                    j += 1\n",
    "                    continue\n",
    "                dur_ms = (ends[j] - starts[i]).total_seconds() * 1000.0\n",
    "                evs.append({\n",
    "                    \"start\": starts[i],\n",
    "                    \"end\": ends[j],\n",
    "                    \"duration_ms\": dur_ms,\n",
    "                    \"olf_id\": olf_id,\n",
    "                    \"idx\": idx,\n",
    "                    \"col\": col,\n",
    "                })\n",
    "                i += 1\n",
    "                j += 1\n",
    "        evs.sort(key=lambda e: e[\"start\"])\n",
    "        return evs\n",
    "\n",
    "    # --- Build completed trials dataframe and inter-odor windows ---\n",
    "    cls = trial_outcomes_complete.get(\"classification\", trial_outcomes_complete)\n",
    "    completed_keys = [\n",
    "        \"completed_sequence_rewarded\",\n",
    "        \"completed_sequence_unrewarded\",\n",
    "        \"completed_sequence_reward_timeout\",\n",
    "    ]\n",
    "    completed_dfs = [cls[k] for k in completed_keys if k in cls and isinstance(cls[k], pd.DataFrame)]\n",
    "    completed_df = pd.concat(completed_dfs, ignore_index=True) if completed_dfs else pd.DataFrame()\n",
    "\n",
    "    def _trial_id(row):\n",
    "        for k in [\"trial_id\", \"trial_index\", \"sequence_index\", \"Trial\", \"Sequence\", \"trial\"]:\n",
    "            if k in row and pd.notna(row[k]):\n",
    "                return row[k]\n",
    "        return row.name\n",
    "\n",
    "    # Collect inter-odor windows per trial: [(trial_id, pos_i, pos_j, win_start, win_end)]\n",
    "    windows = []\n",
    "    for _, row in completed_df.iterrows():\n",
    "        pov = row.get(\"position_valve_times\")\n",
    "        if not isinstance(pov, dict) or not pov:\n",
    "            continue\n",
    "        tid = _trial_id(row)\n",
    "        # sort positions by position number\n",
    "        positions = sorted([p for p in pov.keys() if isinstance(p, (int, np.integer))])\n",
    "        # windows between consecutive positions\n",
    "        for i in range(len(positions) - 1):\n",
    "            p_i = positions[i]\n",
    "            p_j = positions[i + 1]\n",
    "            end_i = pov[p_i].get(\"valve_end\")\n",
    "            start_j = pov[p_j].get(\"valve_start\")\n",
    "            if pd.isna(end_i) or pd.isna(start_j) or end_i is None or start_j is None:\n",
    "                continue\n",
    "            if end_i >= start_j:\n",
    "                # overlapping/invalid; skip\n",
    "                continue\n",
    "            win_start = end_i - pd.Timedelta(milliseconds=onset_slack_ms)\n",
    "            win_end = start_j + pd.Timedelta(milliseconds=onset_slack_ms)\n",
    "            windows.append((tid, p_i, p_j, win_start, win_end))\n",
    "\n",
    "    # --- Scan purge events and match onsets within windows ---\n",
    "    purge_events = _purge_events(odor_map)\n",
    "    starts = [e[\"start\"] for e in purge_events]\n",
    "\n",
    "    matches = []\n",
    "    for tid, p_i, p_j, ws, we in windows:\n",
    "        lo = bisect_left(starts, ws)\n",
    "        hi = bisect_right(starts, we)\n",
    "        for k in range(lo, hi):\n",
    "            e = purge_events[k]\n",
    "            if e[\"duration_ms\"] < threshold_ms:\n",
    "                matches.append({\n",
    "                    \"trial_id\": tid,\n",
    "                    \"from_pos\": p_i,\n",
    "                    \"to_pos\": p_j,\n",
    "                    \"start\": e[\"start\"],\n",
    "                    \"end\": e[\"end\"],\n",
    "                    \"duration_ms\": e[\"duration_ms\"],\n",
    "                    \"olf_id\": e[\"olf_id\"],\n",
    "                    \"col\": e[\"col\"],\n",
    "                })\n",
    "\n",
    "    # Summary/print\n",
    "    if verbose:\n",
    "        print(f\"Short Purge events (< {threshold_ms} ms) between odors in completed trials \"\n",
    "              f\"(onset slack ±{onset_slack_ms} ms): {len(matches)}\")\n",
    "        by_trial = {}\n",
    "        for m in matches:\n",
    "            by_trial.setdefault(m[\"trial_id\"], 0)\n",
    "            by_trial[m[\"trial_id\"]] += 1\n",
    "        if matches:\n",
    "            for m in sorted(matches, key=lambda x: (x[\"trial_id\"], x[\"start\"])):\n",
    "                print(f\"- trial {m['trial_id']} pos {m['from_pos']}->{m['to_pos']}: \"\n",
    "                      f\"{m['start'].isoformat()} -> {m['end'].isoformat()} \"\n",
    "                      f\"({m['duration_ms']:.1f} ms)  olf {m['olf_id']} col '{m['col']}'\")\n",
    "            print(\"\\nCounts by trial:\")\n",
    "            for tid in sorted(by_trial):\n",
    "                print(f\"  trial {tid}: {by_trial[tid]}\")\n",
    "\n",
    "    return matches\n",
    "\n",
    "# Example usage:\n",
    "matches = list_short_purge_between_odors(trial_outcomes_complete, odor_map, threshold_ms=200.0, onset_slack_ms=100.0, verbose=True)\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a schema file, check any poke that is < threshold (e.g. 200 ms), within completed sequences\n",
    "import pandas as pd\n",
    "import json, ast\n",
    "from pathlib import Path\n",
    "from collections.abc import Mapping\n",
    "\n",
    "def _parse_obj(x):\n",
    "    if isinstance(x, (dict, list, tuple)):\n",
    "        return x\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    if isinstance(x, str):\n",
    "        s = x.strip()\n",
    "        if not s:\n",
    "            return None\n",
    "        # Try JSON first, then Python literal\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return ast.literal_eval(s)\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def _iter_pos_items(ppt):\n",
    "    # Yield (position, info_dict) for dict/list\n",
    "    if isinstance(ppt, Mapping):\n",
    "        for k, v in ppt.items():\n",
    "            if not isinstance(v, Mapping):\n",
    "                try:\n",
    "                    v = dict(v)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            pos = v.get(\"position\")\n",
    "            if pos is None:\n",
    "                try:\n",
    "                    pos = int(k)\n",
    "                except Exception:\n",
    "                    pos = k\n",
    "            yield pos, v\n",
    "    elif isinstance(ppt, (list, tuple)):\n",
    "        for v in ppt:\n",
    "            if isinstance(v, Mapping):\n",
    "                yield v.get(\"position\"), v\n",
    "\n",
    "def _normalize_valves(pvt):\n",
    "    # Normalize to dict: position -> valve dict\n",
    "    out = {}\n",
    "    if isinstance(pvt, Mapping):\n",
    "        items = list(pvt.items())\n",
    "    elif isinstance(pvt, (list, tuple)):\n",
    "        items = [(v.get(\"position\"), v) for v in pvt if isinstance(v, Mapping)]\n",
    "    else:\n",
    "        items = []\n",
    "    for k, v in items:\n",
    "        if not isinstance(v, Mapping):\n",
    "            try:\n",
    "                v = dict(v)\n",
    "            except Exception:\n",
    "                v = {}\n",
    "        pos = v.get(\"position\")\n",
    "        if pos is None:\n",
    "            try:\n",
    "                pos = int(k)\n",
    "            except Exception:\n",
    "                pos = k\n",
    "        out[pos] = v\n",
    "    return out\n",
    "\n",
    "def extract_short_pokes_from_saved(schema_path: str | Path, threshold_ms: float = 200.0) -> pd.DataFrame:\n",
    "    schema_path = Path(schema_path)\n",
    "    csv_path = schema_path.with_suffix(\"\").with_suffix(\".csv\")  # replace .schema.json -> .csv\n",
    "    if not csv_path.exists():\n",
    "        # fallback: try sibling CSV with same stem\n",
    "        csv_path = schema_path.parent / (schema_path.stem.replace(\".schema\", \"\") + \".csv\")\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"CSV not found next to schema: {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Identify column names for per-position fields\n",
    "    poke_col = None\n",
    "    valve_col = None\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if poke_col is None and \"position\" in lc and \"poke\" in lc:\n",
    "            poke_col = c\n",
    "        if valve_col is None and \"position\" in lc and \"valve\" in lc:\n",
    "            valve_col = c\n",
    "    if poke_col is None:\n",
    "        raise KeyError(\"Could not find position_poke_times column in CSV\")\n",
    "    if valve_col is None:\n",
    "        # some outputs may not store per-position valves; still proceed\n",
    "        valve_col = None\n",
    "\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        ppt = _parse_obj(row.get(poke_col))\n",
    "        if ppt is None:\n",
    "            continue\n",
    "        pvt_raw = _parse_obj(row.get(valve_col)) if valve_col else None\n",
    "        valve_map = _normalize_valves(pvt_raw) if pvt_raw is not None else {}\n",
    "\n",
    "        run_id = row.get(\"run_id\")\n",
    "        trial_id = row.get(\"trial_id\")\n",
    "\n",
    "        for pos, info in _iter_pos_items(ppt):\n",
    "            if not isinstance(info, Mapping):\n",
    "                try:\n",
    "                    info = dict(info)\n",
    "                except Exception:\n",
    "                    continue\n",
    "            poke_ms = pd.to_numeric(info.get(\"poke_time_ms\"), errors=\"coerce\")\n",
    "            if pd.isna(poke_ms) or poke_ms <= 0 or poke_ms >= threshold_ms:\n",
    "                continue\n",
    "\n",
    "            # normalize pos\n",
    "            try:\n",
    "                pos_norm = int(pos) if pos is not None else None\n",
    "            except Exception:\n",
    "                pos_norm = pos\n",
    "\n",
    "            vt = valve_map.get(pos_norm, {})\n",
    "            odor = info.get(\"odor_name\") or (vt or {}).get(\"odor_name\")\n",
    "            first_in = info.get(\"poke_first_in\")\n",
    "            valve_open = (vt or {}).get(\"valve_open_ts\")\n",
    "            valve_close = (vt or {}).get(\"valve_close_ts\")\n",
    "            event_ts = first_in if first_in is not None else valve_open  # measurement start\n",
    "\n",
    "            rows.append({\n",
    "                \"run_id\": run_id,\n",
    "                \"trial_id\": trial_id,\n",
    "                \"position\": pos_norm,\n",
    "                \"odor\": odor,\n",
    "                \"poke_ms\": float(poke_ms),\n",
    "                \"event_ts\": event_ts,\n",
    "                \"valve_open_ts\": valve_open,\n",
    "                \"valve_close_ts\": valve_close,\n",
    "                \"poke_first_in\": first_in,\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    if not out.empty:\n",
    "        out[\"event_ts\"] = pd.to_datetime(out[\"event_ts\"], errors=\"coerce\")\n",
    "        out = out.sort_values([\"run_id\",\"trial_id\",\"position\",\"event_ts\"], kind=\"stable\", na_position=\"last\").reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# Use your saved path\n",
    "schema_path = \"/Volumes/harris/hypnose/derivatives/sub-040_id-259/ses-022_date-20251125/saved_analysis_results/completed_sequences_with_response_times.schema.json\"\n",
    "short_pokes = extract_short_pokes_from_saved(schema_path, threshold_ms=200.0)\n",
    "display(short_pokes)\n",
    "print(f\"{len(short_pokes)} positions with poke_time_ms < 200 ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify trial IDs for trials with poke time bewlow threshold \n",
    "threshold_ms = 200.0\n",
    "\n",
    "# Get the classification DataFrames\n",
    "cls = trial_outcomes_complete.get(\"classification\", trial_outcomes_complete)\n",
    "\n",
    "completed_keys = [\n",
    "    \"completed_sequence_rewarded\",\n",
    "    \"completed_sequence_unrewarded\",\n",
    "    \"completed_sequence_reward_timeout\",\n",
    "]\n",
    "completed_dfs = [cls[k] for k in completed_keys if k in cls and isinstance(cls[k], pd.DataFrame)]\n",
    "completed_df = pd.concat(completed_dfs, ignore_index=True) if completed_dfs else pd.DataFrame()\n",
    "\n",
    "def _trial_id(row):\n",
    "    for k in [\"trial_id\", \"trial_index\", \"sequence_index\", \"Trial\", \"Sequence\", \"trial\"]:\n",
    "        if k in row and pd.notna(row[k]):\n",
    "            return row[k]\n",
    "    return row.name  # fallback\n",
    "\n",
    "hits = []\n",
    "for _, row in completed_df.iterrows():\n",
    "    pos_pokes = row.get(\"position_poke_times\")\n",
    "    if not isinstance(pos_pokes, dict):\n",
    "        continue\n",
    "    tid = _trial_id(row)\n",
    "    for pos, info in pos_pokes.items():\n",
    "        if not isinstance(info, dict):\n",
    "            continue\n",
    "        ms = info.get(\"poke_time_ms\")\n",
    "        if ms is None:\n",
    "            continue\n",
    "        if ms < threshold_ms:\n",
    "            odor = info.get(\"odor_name\")\n",
    "            hits.append((ms, tid, pos, odor))\n",
    "\n",
    "# Print results sorted by poke time\n",
    "if not hits:\n",
    "    print(f\"No completed-trial positions with poke_time_ms < {threshold_ms} ms found.\")\n",
    "else:\n",
    "    hits.sort(key=lambda x: x[0])\n",
    "    print(f\"Trials with poke_time_ms < {threshold_ms} ms (n={len(hits)}):\")\n",
    "    for ms, tid, pos, odor in hits:\n",
    "        print(f\"- trial {tid}, position {pos}, {odor}: {ms:.1f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypnose-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
